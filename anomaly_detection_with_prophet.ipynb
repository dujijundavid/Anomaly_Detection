{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980dc39c",
   "metadata": {},
   "source": [
    "## Train & Inference Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9ac0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-12T17:17:52.525Z"
    }
   },
   "outputs": [],
   "source": [
    "script_option = \"Train\"\n",
    "#script_option = \"Inference\"\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 1: Set Ups -------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from pandas_profiling import ProfileReport\n",
    "import datetime\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fit_model(dataframe, interval_width=0.99, changepoint_range=0.8):\n",
    "    '''\n",
    "        Input: \n",
    "\n",
    "        Output: a forecasted dataframe includes\n",
    "\n",
    "    '''\n",
    "\n",
    "    m = Prophet(daily_seasonality=False, yearly_seasonality=False, weekly_seasonality=False,\n",
    "                seasonality_mode='multiplicative',\n",
    "                interval_width=interval_width,\n",
    "                changepoint_range=changepoint_range)\n",
    "    m = m.fit(dataframe)\n",
    "    return m\n",
    "    \n",
    "\n",
    "def predict_model(dataframe,m):\n",
    "    forecast = m.predict(dataframe)\n",
    "    forecast['fact'] = dataframe['y'].reset_index(drop=True)\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "\n",
    "def detect_anomalies(forecast):\n",
    "    '''\n",
    "    What it does:  based on rule: label anomaly data point based on whether the actual data is greater than the upper bond of prediction or smaller than the lower bond of the prediction.\n",
    "\n",
    "    Input: forecast dataframe from Prophet model.\n",
    "    Output: forecast dataframe with anomlies labeled. \n",
    "\n",
    "    '''\n",
    "    forecasted = forecast[['ds', 'trend', 'yhat',\n",
    "                           'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] >\n",
    "                   forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] <\n",
    "                   forecasted['yhat_lower'], 'anomaly'] = -1\n",
    "\n",
    "    # anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] == 1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] == -1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "\n",
    "    return forecasted\n",
    "\n",
    "# Export Anomaly_df is a python Dataframe object.\n",
    "# MySQL Insert Query includes [tableName], (columns to insert)\n",
    "# The value stores (col1, col2,col3)\n",
    "def insert_anomalies_prophet(current_anomlies):\n",
    "    for index, row in current_anomlies.iterrows():\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"10.1.2.10\",\n",
    "            user=\"gyan\",\n",
    "            password=\"5Gaa$2022\",\n",
    "            database=\"gyan_db\"\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        MySQL_insert_query = \"INSERT INTO tb_export_anomaly_df (client_id, stats_timestamp, attribute_name, attribute_value, attribute_label_prophet, attribute_deviation,attribute_mean) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        the_value= (row.client_id, str(row.stats_timestamp), str(row.attribute_label), row.attribute_value, row.attribute_label_prophet, row.attribute_deviation,row.attribute_mean)\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(MySQL_insert_query, the_value)\n",
    "            connection.commit()\n",
    "        except:\n",
    "            print(\"Record Already Inserted\")\n",
    "            pass\n",
    "\n",
    "    cursor.close()\n",
    "    print(\"Insert Complete\")\n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 2: Data and DB connetion -----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Initiate with Parameters\n",
    "db_name = \"core_stats\"\n",
    "col = \"peak_upload_speed\"\n",
    "\n",
    "\n",
    "# Start Database Connection\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"10.1.2.10\",\n",
    "    user=\"gyan\",\n",
    "    password=\"5Gaa$2022\",\n",
    "    database=\"gyan_db\"\n",
    ")\n",
    "\n",
    "# Load data from database and store as pandas Dataframe\n",
    "df_rand = pd.read_sql(\n",
    "    'SELECT * FROM gyan_db.core_stats WHERE client_id= \"BETBEL01GYN001\" AND stats_timestamp>\"2022-07-15\"'.format(db_name), con=db_connection)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 3: Prophet Model Training ----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "df_rand_prophet = df_rand[[\"stats_timestamp\", \"peak_upload_speed\"]].rename(\n",
    "    columns={\"stats_timestamp\": \"ds\", \"peak_upload_speed\": \"y\"})\n",
    "\n",
    "rand_list = ['total_attached_user',\n",
    "             'total_rejected_user', 'peak_upload_speed', 'peak_download_speed',\n",
    "             'enodeb_shutdown_count', 'handover_failure_count',\n",
    "             'bearer_active_user_count', 'bearer_rejected_user_count', 'total_users',\n",
    "             'total_dropped_packets', 'enodeb_connected_count',\n",
    "             'enodeb_connection_status']\n",
    "\n",
    "\n",
    "anomaly_df = pd.DataFrame()\n",
    "for item in rand_list:\n",
    "    print(item)\n",
    "    df_rand_prophet = df_rand[[\"stats_timestamp\", item]].rename(\n",
    "        columns={\"stats_timestamp\": \"ds\", item: \"y\"})\n",
    "    \n",
    "    json_path = \"prophet_models/\"+\"BETBEL01GYN001\"+str(item)+\".json\"\n",
    "    folder_path = \"/opt/gyan/gyan-anomaly-detector\"\n",
    "    \n",
    "    if script_option == \"Train\":\n",
    "        \n",
    "        model = fit_model(df_rand_prophet)\n",
    "\n",
    "            \n",
    "        with open(json_path, 'w') as fout:\n",
    "            fout.write(model_to_json(model))  # Save model\n",
    "\n",
    "    elif script_option==\"Inference\":  \n",
    "      \n",
    "        with open(json_path, 'r') as fin:\n",
    "            model = model_from_json(fin.read())  # Load model\n",
    "\n",
    "        pred = predict_model(df_rand_prophet,model)\n",
    "        pred_anomalies = detect_anomalies(pred)\n",
    "        print(\"Anomaly rate is: \", pred_anomalies[\"anomaly\"].sum()/pred_anomalies.shape[0])\n",
    "    \n",
    "    \n",
    "        sub_anomaly_df = pred_anomalies[(pred_anomalies[\"anomaly\"]==-1) | (pred_anomalies[\"anomaly\"]==1)]\n",
    "        sub_anomaly_df[\"attribute_label\"]=item\n",
    "        anomaly_df=anomaly_df.append(sub_anomaly_df, ignore_index = True)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 4: Get Current Anomalies and Insert-----------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "if script_option==\"Inference\":\n",
    "    anomaly_df= anomaly_df.rename(columns= {\"ds\":\"stats_timestamp\",\"yhat\":\"attribute_mean\",\"anomaly\":\"attribute_label_prophet\",\"fact\":\"attribute_value\",\"importance\":\"attribute_deviation\"})\n",
    "    anomaly_df=anomaly_df.drop([\"trend\",\"yhat_lower\",\"yhat_upper\"],axis=1)\n",
    "    anomaly_df[\"client_id\"]= \"BETBEL01GYN001\"\n",
    "    \n",
    "    time_interval = datetime.datetime.now() - datetime.timedelta(minutes=120)\n",
    "    current_anomlies= anomaly_df[anomaly_df.stats_timestamp > time_interval].reset_index()\n",
    "\n",
    "\n",
    "    if current_anomlies.shape[0]>0:\n",
    "        insert_anomalies_prophet(current_anomlies)\n",
    "        print(\"Anomalies Insert Completed\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"No Anomalies Detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa763f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:29:21.416492Z",
     "start_time": "2022-09-06T21:29:21.416492Z"
    }
   },
   "outputs": [],
   "source": [
    "# pkl_path = \"prophet_models/\"+\"BETBEL01GYN001\"+str(item)+\".pkl\"\n",
    "\n",
    "# with open(pkl_path, \"wb\") as f:\n",
    "# # Pickle the 'Prophet' model using the highest protocol available.\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "# with open(pkl_path, 'rb') as f:\n",
    "#     model = pickle.load(f)\n",
    "\n",
    "\n",
    "# save the dataframe\n",
    "# forecast.to_pickle(\"path/to/data/forecast.pkl\")\n",
    "# print(\"*** Data Saved ***\")\n",
    "\n",
    "#fcast = pd.read_pickle(\"path/to/data/forecast.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7c187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:29:21.417492Z",
     "start_time": "2022-09-06T21:29:21.417492Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# script_option = \"Train\"\n",
    "\n",
    "# if script_option == \"Train\":\n",
    "#     with open(\"BETBEL01GYN001\"+str(item)+'.json', 'w') as fout:\n",
    "#         fout.write(model_to_json(model))  # Save model\n",
    "\n",
    "# with open(\"BETBEL01GYN001\"+str(item)+'.json', 'r') as fin:\n",
    "#     m = model_from_json(fin.read())  # Load model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed3e2e",
   "metadata": {},
   "source": [
    "## Base Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f24689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T22:41:04.889778Z",
     "start_time": "2022-09-06T22:27:51.903501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_attached_user\n",
      "Anomaly rate is:  0.0010148751703540466\n",
      "total_rejected_user\n",
      "Anomaly rate is:  0.00031896076782555744\n",
      "peak_upload_speed\n",
      "Anomaly rate is:  -0.0005509322353350538\n",
      "peak_download_speed\n",
      "Anomaly rate is:  0.0030156290776234525\n",
      "enodeb_shutdown_count\n",
      "Anomaly rate is:  0.00040595006814161857\n",
      "handover_failure_count\n",
      "Anomaly rate is:  0.00020297503407080928\n",
      "bearer_active_user_count\n",
      "Anomaly rate is:  0.00028996433438687044\n",
      "bearer_rejected_user_count\n",
      "Anomaly rate is:  0.00023197146750949634\n",
      "total_users\n",
      "Anomaly rate is:  0.00031896076782555744\n",
      "total_dropped_packets\n",
      "Anomaly rate is:  0.0009278858700379854\n",
      "enodeb_connected_count\n",
      "Anomaly rate is:  0.0002609679009481834\n",
      "enodeb_connection_status\n",
      "Anomaly rate is:  0.0002609679009481834\n",
      "No Anomalies Detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 1: Set Ups -------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from pandas_profiling import ProfileReport\n",
    "import datetime\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fit_model(dataframe, interval_width=0.99, changepoint_range=0.8):\n",
    "    '''\n",
    "        Input: \n",
    "\n",
    "        Output: a forecasted dataframe includes\n",
    "\n",
    "    '''\n",
    "\n",
    "    m = Prophet(daily_seasonality=False, yearly_seasonality=False, weekly_seasonality=False,\n",
    "                seasonality_mode='multiplicative',\n",
    "                interval_width=interval_width,\n",
    "                changepoint_range=changepoint_range)\n",
    "    m = m.fit(dataframe)\n",
    "    return m\n",
    "    \n",
    "\n",
    "def predict_model(dataframe,m):\n",
    "    forecast = m.predict(dataframe)\n",
    "    forecast['fact'] = dataframe['y'].reset_index(drop=True)\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "\n",
    "def detect_anomalies(forecast):\n",
    "    '''\n",
    "    What it does:  based on rule: label anomaly data point based on whether the actual data is greater than the upper bond of prediction or smaller than the lower bond of the prediction.\n",
    "\n",
    "    Input: forecast dataframe from Prophet model.\n",
    "    Output: forecast dataframe with anomlies labeled. \n",
    "\n",
    "    '''\n",
    "    forecasted = forecast[['ds', 'trend', 'yhat',\n",
    "                           'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] >\n",
    "                   forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] <\n",
    "                   forecasted['yhat_lower'], 'anomaly'] = -1\n",
    "\n",
    "    # anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] == 1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] == -1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "\n",
    "    return forecasted\n",
    "\n",
    "# Export Anomaly_df is a python Dataframe object.\n",
    "# MySQL Insert Query includes [tableName], (columns to insert)\n",
    "# The value stores (col1, col2,col3)\n",
    "def insert_anomalies_prophet(current_anomlies):\n",
    "    for index, row in current_anomlies.iterrows():\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"10.1.2.10\",\n",
    "            user=\"gyan\",\n",
    "            password=\"5Gaa$2022\",\n",
    "            database=\"gyan_db\"\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        MySQL_insert_query = \"INSERT INTO tb_export_anomaly_df (client_id, stats_timestamp, attribute_name, attribute_value, attribute_label_prophet, attribute_deviation,attribute_mean) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        the_value= (row.client_id, str(row.stats_timestamp), str(item), row.attribute_value, row.attribute_label_prophet, row.attribute_deviation,row.attribute_mean)\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(MySQL_insert_query, the_value)\n",
    "            connection.commit()\n",
    "        except:\n",
    "            print(\"Record Inserted\")\n",
    "            pass\n",
    "\n",
    "    cursor.close()\n",
    "    print(\"Insert Complete\")\n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 2: Data and DB connetion -----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Initiate with Parameters\n",
    "db_name = \"core_stats\"\n",
    "col = \"peak_upload_speed\"\n",
    "\n",
    "\n",
    "# Start Database Connection\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"10.1.2.10\",\n",
    "    user=\"gyan\",\n",
    "    password=\"5Gaa$2022\",\n",
    "    database=\"gyan_db\"\n",
    ")\n",
    "\n",
    "# Load data from database and store as pandas Dataframe\n",
    "df_rand = pd.read_sql(\n",
    "    'SELECT * FROM gyan_db.core_stats WHERE client_id= \"BETBEL01GYN001\" AND stats_timestamp>\"2022-07-15\"'.format(db_name), con=db_connection)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 3: Prophet Model Training ----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "df_rand_prophet = df_rand[[\"stats_timestamp\", \"peak_upload_speed\"]].rename(\n",
    "    columns={\"stats_timestamp\": \"ds\", \"peak_upload_speed\": \"y\"})\n",
    "\n",
    "rand_list = ['total_attached_user',\n",
    "             'total_rejected_user', 'peak_upload_speed', 'peak_download_speed',\n",
    "             'enodeb_shutdown_count', 'handover_failure_count',\n",
    "             'bearer_active_user_count', 'bearer_rejected_user_count', 'total_users',\n",
    "             'total_dropped_packets', 'enodeb_connected_count',\n",
    "             'enodeb_connection_status']\n",
    "\n",
    "\n",
    "anomaly_df = pd.DataFrame()\n",
    "for item in rand_list:\n",
    "    print(item)\n",
    "    df_rand_prophet = df_rand[[\"stats_timestamp\", item]].rename(\n",
    "    columns={\"stats_timestamp\": \"ds\", item: \"y\"})\n",
    "    model = fit_model(df_rand_prophet)\n",
    "\n",
    "    pred = predict_model(df_rand_prophet,model)\n",
    "    pred_anomalies = detect_anomalies(pred)\n",
    "    print(\"Anomaly rate is: \", pred_anomalies[\"anomaly\"].sum()/pred_anomalies.shape[0])\n",
    "\n",
    "\n",
    "    sub_anomaly_df = pred_anomalies[(pred_anomalies[\"anomaly\"]==-1) | (pred_anomalies[\"anomaly\"]==1)]\n",
    "\n",
    "    anomaly_df=anomaly_df.append(sub_anomaly_df, ignore_index = True)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 4: Get Current Anomalies and Insert-----------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "anomaly_df= anomaly_df.rename(columns= {\"ds\":\"stats_timestamp\",\"yhat\":\"attribute_mean\",\"anomaly\":\"attribute_label_prophet\",\"fact\":\"attribute_value\",\"importance\":\"attribute_deviation\"})\n",
    "anomaly_df=anomaly_df.drop([\"trend\",\"yhat_lower\",\"yhat_upper\"],axis=1)\n",
    "anomaly_df[\"client_id\"]= \"BETBEL01GYN001\"\n",
    "\n",
    "time_interval = datetime.datetime.now() - datetime.timedelta(minutes=5)\n",
    "current_anomlies= anomaly_df[anomaly_df.stats_timestamp > time_interval].reset_index()\n",
    "\n",
    "\n",
    "if current_anomlies.shape[0]>0:\n",
    "    insert_anomalies_prophet(current_anomlies)\n",
    "    print(\"Anomalies Insert Completed\")\n",
    "else:\n",
    "    print(\"No Anomalies Detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459bd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
