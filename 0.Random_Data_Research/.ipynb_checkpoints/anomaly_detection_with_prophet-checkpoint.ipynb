{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980dc39c",
   "metadata": {},
   "source": [
    "## Train & Inference Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0d18a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T18:05:02.736498Z",
     "start_time": "2022-09-21T18:05:02.212343Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv(\"Existing_rand_data_after_July15.csv\")[30000:].reset_index(drop=True)\n",
    "\n",
    "df = pd.read_csv(\"randomized_data_with_distribution_1year_V2.csv\")[65000:80000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c9ac0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T18:06:12.547118Z",
     "start_time": "2022-09-21T18:05:02.737775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_attached_user\n",
      "total_rejected_user\n",
      "peak_upload_speed\n",
      "peak_download_speed\n",
      "enodeb_shutdown_count\n",
      "handover_failure_count\n",
      "bearer_active_user_count\n",
      "bearer_rejected_user_count\n",
      "total_users\n",
      "total_dropped_packets\n",
      "enodeb_connected_count\n",
      "enodeb_connection_status\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#script_option = \"Train\"\n",
    "script_option = \"Inference\"\n",
    "# json_path_folder= \"prophet_models/Random_Data_V1/\"\n",
    "# anomaly_graphs_folder=\"Anomaly_graphs/V1_No_Distribution/\"\n",
    "\n",
    "\n",
    "json_path_folder= \"prophet_models/Random_Data_V2/\"\n",
    "anomaly_graphs_folder=\"Anomaly_graphs/V2_Distribution/\"\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 1: Set Ups -------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "from pandas_profiling import ProfileReport\n",
    "import datetime\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fit_model(dataframe, interval_width=0.99, changepoint_range=0.8):\n",
    "    '''\n",
    "        Input: \n",
    "\n",
    "        Output: a forecasted dataframe includes\n",
    "\n",
    "    '''\n",
    "\n",
    "    m = Prophet(daily_seasonality=False, yearly_seasonality=False, weekly_seasonality=False,\n",
    "                seasonality_mode='multiplicative',\n",
    "                interval_width=interval_width,\n",
    "                changepoint_range=changepoint_range)\n",
    "    m = m.fit(dataframe)\n",
    "    return m\n",
    "    \n",
    "\n",
    "\n",
    "def plot_anomalies(forecasted):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    import altair as alt\n",
    "    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color='#7FC97F').encode(\n",
    "        x=alt.X('ds:T',  title='date'),\n",
    "        y='yhat_upper',\n",
    "        y2='yhat_lower',\n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive().properties(\n",
    "        title='Anomaly Detection'\n",
    "    )\n",
    "\n",
    "    fact = alt.Chart(forecasted[forecasted.anomaly == 0]).mark_circle(size=15, opacity=0.7, color='Black').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='sales'),\n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive()\n",
    "\n",
    "    anomalies = alt.Chart(forecasted[forecasted.anomaly != 0]).mark_circle(size=30, color='Red').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='PeakUpload Speed'),\n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper'],\n",
    "        size=alt.Size('importance', legend=None)\n",
    "    ).interactive()\n",
    "\n",
    "    return alt.layer(interval, fact, anomalies)\\\n",
    "              .properties(width=870, height=450)\\\n",
    "              .configure_title(fontSize=20)\n",
    "\n",
    "\n",
    "def predict_model(dataframe,m):\n",
    "    forecast = m.predict(dataframe)\n",
    "    forecast['fact'] = dataframe['y'].reset_index(drop=True)\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "\n",
    "def detect_anomalies(forecast):\n",
    "    '''\n",
    "    What it does:  based on rule: label anomaly data point based on whether the actual data is greater than the upper bond of prediction or smaller than the lower bond of the prediction.\n",
    "\n",
    "    Input: forecast dataframe from Prophet model.\n",
    "    Output: forecast dataframe with anomlies labeled. \n",
    "\n",
    "    '''\n",
    "    forecasted = forecast[['ds', 'trend', 'yhat',\n",
    "                           'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] >\n",
    "                   forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] <\n",
    "                   forecasted['yhat_lower'], 'anomaly'] = -1\n",
    "\n",
    "    # anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] == 1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] == -1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "\n",
    "    return forecasted\n",
    "\n",
    "# Export Anomaly_df is a python Dataframe object.\n",
    "# MySQL Insert Query includes [tableName], (columns to insert)\n",
    "# The value stores (col1, col2,col3)\n",
    "def insert_anomalies_prophet(current_anomlies):\n",
    "    for index, row in current_anomlies.iterrows():\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"10.1.2.10\",\n",
    "            user=\"gyan\",\n",
    "            password=\"5Gaa$2022\",\n",
    "            database=\"gyan_db\"\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        MySQL_insert_query = \"INSERT INTO tb_export_anomaly_df (client_id, stats_timestamp, attribute_name, attribute_value, attribute_label_prophet, attribute_deviation,attribute_mean) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        the_value= (row.client_id, str(row.stats_timestamp), str(row.attribute_label), row.attribute_value, row.attribute_label_prophet, row.attribute_deviation,row.attribute_mean)\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(MySQL_insert_query, the_value)\n",
    "            connection.commit()\n",
    "        except:\n",
    "            print(\"Record Already Inserted\")\n",
    "            pass\n",
    "\n",
    "    cursor.close()\n",
    "    print(\"Insert Complete\")\n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 2: Data and DB connetion -----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 3: Prophet Model Training ----------------------------\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "rand_list = ['total_attached_user',\n",
    "             'total_rejected_user', 'peak_upload_speed', 'peak_download_speed',\n",
    "             'enodeb_shutdown_count', 'handover_failure_count',\n",
    "             'bearer_active_user_count', 'bearer_rejected_user_count', 'total_users',\n",
    "             'total_dropped_packets', 'enodeb_connected_count',\n",
    "             'enodeb_connection_status']\n",
    "\n",
    "\n",
    "anomaly_df = pd.DataFrame()\n",
    "for item in rand_list:\n",
    "    print(item)\n",
    "    df_rand_prophet = df[[\"stats_timestamp\", item]].rename(\n",
    "        columns={\"stats_timestamp\": \"ds\", item: \"y\"})\n",
    "\n",
    "    json_path = json_path_folder+\"RAND001\"+str(item)+\".json\"\n",
    "\n",
    "    if script_option == \"Train\":\n",
    "\n",
    "        model = fit_model(df_rand_prophet)\n",
    "\n",
    "\n",
    "        with open(json_path, 'w') as fout:\n",
    "            fout.write(model_to_json(model))  # Save model\n",
    "\n",
    "    elif script_option==\"Inference\":  \n",
    "\n",
    "        with open(json_path, 'r') as fin:\n",
    "            model = model_from_json(fin.read())  # Load model\n",
    "\n",
    "        pred = predict_model(df_rand_prophet,model)\n",
    "        pred_anomalies = detect_anomalies(pred)\n",
    "        print(\"Anomaly rate is: \", pred_anomalies[\"anomaly\"].sum()/pred_anomalies.shape[0])\n",
    "\n",
    "\n",
    "        sub_anomaly_df = pred_anomalies[(pred_anomalies[\"anomaly\"]==-1) | (pred_anomalies[\"anomaly\"]==1)]\n",
    "        sub_anomaly_df[\"attribute_label\"]=item\n",
    "        anomaly_df=anomaly_df.append(sub_anomaly_df, ignore_index = True)\n",
    "\n",
    "\n",
    "        chart = plot_anomalies(pred_anomalies[:5000])\n",
    "\n",
    "        chart.save(anomaly_graphs_folder+'Anomaly_{}.html'.format(item))\n",
    "\n",
    "\n",
    "#         chart2 = plot_anomalies(pred_anomalies[5000:10000])\n",
    "\n",
    "#         chart2.save(\"Anomaly_graphs/V1_Long_period_anomalies/\"+'Anomaly_{}.html'.format(item))\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#---------------------------------Part 4: Get Current Anomalies and Insert-----------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "if script_option==\"Inference\":\n",
    "    anomaly_df= anomaly_df.rename(columns= {\"ds\":\"stats_timestamp\",\"yhat\":\"attribute_mean\",\"anomaly\":\"attribute_label_prophet\",\"fact\":\"attribute_value\",\"importance\":\"attribute_deviation\"})\n",
    "    anomaly_df=anomaly_df.drop([\"trend\",\"yhat_lower\",\"yhat_upper\"],axis=1)\n",
    "    anomaly_df[\"client_id\"]= \"RAND001\"\n",
    "\n",
    "    time_interval = datetime.datetime.now() - datetime.timedelta(minutes=120)\n",
    "    current_anomlies= anomaly_df[anomaly_df.stats_timestamp > time_interval].reset_index()\n",
    "\n",
    "\n",
    "    if current_anomlies.shape[0]>0:\n",
    "        insert_anomalies_prophet(current_anomlies)\n",
    "        print(\"Anomalies Insert Completed\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"No Anomalies Detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ddf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
